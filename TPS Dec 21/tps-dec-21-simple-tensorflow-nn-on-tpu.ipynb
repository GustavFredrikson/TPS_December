{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ecf18c",
   "metadata": {
    "papermill": {
     "duration": 0.01818,
     "end_time": "2021-12-13T11:44:24.032276",
     "exception": false,
     "start_time": "2021-12-13T11:44:24.014096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# My application of a simple neural net on playground december 2021\n",
    "### Please let me know of any improvements, I'm here to learn\n",
    "\n",
    "### Ideas for improvement\n",
    "* Feature engineering, Cover_Type = 5 is only 1 sample, remove? DONE\n",
    "* Encode using sklearn labelencoder (need to use encoder.inverse_transform for test preds later) DONE\n",
    "* Scale data using sklearn robustscaler DONE\n",
    "* Plot model using tf.keras.utils plot_model\n",
    "* Use some tool to do feature importance\n",
    "* Can run on TPU, DONE\n",
    "\n",
    "Used https://www.kaggle.com/gulshanmishra/tps-dec-21-tensorflow-nn-feature-engineering as inspiration, please go give that notebook a thumbs up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f8ec9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:44:24.085759Z",
     "iopub.status.busy": "2021-12-13T11:44:24.082294Z",
     "iopub.status.idle": "2021-12-13T11:44:29.996142Z",
     "shell.execute_reply": "2021-12-13T11:44:29.995518Z",
     "shell.execute_reply.started": "2021-12-13T11:39:42.864139Z"
    },
    "papermill": {
     "duration": 5.948402,
     "end_time": "2021-12-13T11:44:29.996296",
     "exception": false,
     "start_time": "2021-12-13T11:44:24.047894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datatable as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "\n",
    "plot = False # Plot model or plot summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206aab3",
   "metadata": {
    "papermill": {
     "duration": 0.010547,
     "end_time": "2021-12-13T11:44:30.017866",
     "exception": false,
     "start_time": "2021-12-13T11:44:30.007319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to reduce memory of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ecdec7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:44:30.053228Z",
     "iopub.status.busy": "2021-12-13T11:44:30.051653Z",
     "iopub.status.idle": "2021-12-13T11:44:30.053837Z",
     "shell.execute_reply": "2021-12-13T11:44:30.054291Z",
     "shell.execute_reply.started": "2021-12-13T11:39:49.087146Z"
    },
    "papermill": {
     "duration": 0.025919,
     "end_time": "2021-12-13T11:44:30.054419",
     "exception": false,
     "start_time": "2021-12-13T11:44:30.028500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e56a3",
   "metadata": {
    "papermill": {
     "duration": 0.01011,
     "end_time": "2021-12-13T11:44:30.074734",
     "exception": false,
     "start_time": "2021-12-13T11:44:30.064624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing training and testing data\n",
    "Reading using datatable and converting to pandas is often faster than reading directly using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1ee624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:44:30.103664Z",
     "iopub.status.busy": "2021-12-13T11:44:30.103029Z",
     "iopub.status.idle": "2021-12-13T11:44:44.885711Z",
     "shell.execute_reply": "2021-12-13T11:44:44.885238Z",
     "shell.execute_reply.started": "2021-12-13T11:39:49.103102Z"
    },
    "papermill": {
     "duration": 14.800996,
     "end_time": "2021-12-13T11:44:44.885844",
     "exception": false,
     "start_time": "2021-12-13T11:44:30.084848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 63.90 Mb (23.9% reduction)\n",
      "Mem. usage decreased to 259.40 Mb (26.1% reduction)\n",
      "Nr of cover_type = 5: 1\n",
      "Nr of cover_type = 4: 377\n"
     ]
    }
   ],
   "source": [
    "train_df = dt.fread(\"../input/tabular-playground-series-dec-2021/train.csv\")\n",
    "test_df = dt.fread(\"../input/tabular-playground-series-dec-2021/test.csv\")\n",
    "test_df = reduce_memory_usage(test_df.to_pandas())\n",
    "train_df = reduce_memory_usage(train_df.to_pandas())\n",
    "\n",
    "INPUT_SHAPE = test_df.shape[1:] # Used to decide first layer of nn\n",
    "NUM_CLASSES = train_df[\"Cover_Type\"].nunique() # For output layer of nn\n",
    "\n",
    "# Remove sample with cover_type = 5\n",
    "idx_to_drop5 = train_df[train_df[\"Cover_Type\"] == 5].index\n",
    "print(f\"Nr of cover_type = 5: {len(idx_to_drop5)}\")\n",
    "train_df.drop(idx_to_drop5,\n",
    "              axis=0,\n",
    "              inplace=True)\n",
    "\n",
    "# Very few is 4 aswell\n",
    "\"\"\"idx_to_drop4 = train_df[train_df[\"Cover_Type\"] == 4].index\n",
    "print(f\"Nr of cover_type = 4: {len(idx_to_drop4)}\")\n",
    "train_df.drop(idx_to_drop4,\n",
    "              axis=0,\n",
    "              inplace=True)\"\"\"\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_df[\"Cover_Type\"] = encoder.fit_transform(train_df[\"Cover_Type\"])\n",
    "\n",
    "bool_features = [i for i in train_df.columns if \"area\" in i.lower() or \"soil\" in i.lower()]\n",
    "test_df[bool_features] = test_df[bool_features].astype(np.int8)\n",
    "train_df[bool_features] = train_df[bool_features].astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6c92b",
   "metadata": {
    "papermill": {
     "duration": 0.010718,
     "end_time": "2021-12-13T11:44:44.908053",
     "exception": false,
     "start_time": "2021-12-13T11:44:44.897335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Scale unscaled data\n",
    "Great article on interesting ways to select pandas columns:\n",
    "https://towardsdatascience.com/interesting-ways-to-select-pandas-dataframe-columns-b29b82bbfb33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f916aea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:44:44.937023Z",
     "iopub.status.busy": "2021-12-13T11:44:44.936089Z",
     "iopub.status.idle": "2021-12-13T11:44:48.668207Z",
     "shell.execute_reply": "2021-12-13T11:44:48.669291Z",
     "shell.execute_reply.started": "2021-12-13T11:40:06.085866Z"
    },
    "papermill": {
     "duration": 3.750884,
     "end_time": "2021-12-13T11:44:48.669497",
     "exception": false,
     "start_time": "2021-12-13T11:44:44.918613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Columns: Index(['Id', 'Elevation', 'Aspect', 'Slope',\n",
      "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
      "       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
      "       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points'],\n",
      "      dtype='object')\n",
      "\n",
      "  Number of scaled Columns: 11\n"
     ]
    }
   ],
   "source": [
    "cols_to_scale = train_df.loc[:,[(train_df[col] > 7).any() for col in train_df.columns]].columns\n",
    "print(f\"Scaled Columns: {cols_to_scale}\\n\\n  \\\n",
    "Number of scaled Columns: {len(cols_to_scale)}\")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "train_df[cols_to_scale] = scaler.fit_transform(train_df[cols_to_scale])\n",
    "test_df[cols_to_scale] = scaler.fit_transform(test_df[cols_to_scale])\n",
    "\n",
    "y = train_df.pop(\"Cover_Type\").values\n",
    "X = train_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441dea9",
   "metadata": {
    "papermill": {
     "duration": 0.017558,
     "end_time": "2021-12-13T11:44:48.706755",
     "exception": false,
     "start_time": "2021-12-13T11:44:48.689197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Functions to use when training later\n",
    "Reduce learningrate when accuracy is plateauing and stop early if accuracy is not improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f8992b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:44:48.749618Z",
     "iopub.status.busy": "2021-12-13T11:44:48.748783Z",
     "iopub.status.idle": "2021-12-13T11:44:48.750895Z",
     "shell.execute_reply": "2021-12-13T11:44:48.750298Z",
     "shell.execute_reply.started": "2021-12-13T11:40:09.662100Z"
    },
    "papermill": {
     "duration": 0.026354,
     "end_time": "2021-12-13T11:44:48.751045",
     "exception": false,
     "start_time": "2021-12-13T11:44:48.724691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=False\n",
    ")\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=True\n",
    ")\n",
    "callbacks = [reduce_lr, early_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312e5ae9",
   "metadata": {
    "papermill": {
     "duration": 0.011236,
     "end_time": "2021-12-13T11:44:48.781015",
     "exception": false,
     "start_time": "2021-12-13T11:44:48.769779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define the model and compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e2bb6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:44:48.815630Z",
     "iopub.status.busy": "2021-12-13T11:44:48.810377Z",
     "iopub.status.idle": "2021-12-13T11:44:51.356463Z",
     "shell.execute_reply": "2021-12-13T11:44:51.355964Z",
     "shell.execute_reply.started": "2021-12-13T11:40:09.676645Z"
    },
    "papermill": {
     "duration": 2.564675,
     "end_time": "2021-12-13T11:44:51.356585",
     "exception": false,
     "start_time": "2021-12-13T11:44:48.791910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on TPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 11:44:48.932815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 11:44:49.043767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 11:44:49.044844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               28672     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 207,365\n",
      "Trainable params: 205,381\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 11:44:49.047149: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-13 11:44:49.049075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 11:44:49.050063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 11:44:49.051083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 11:44:50.855894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 11:44:50.856803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 11:44:50.857762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 11:44:50.858432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # To run on TPU\n",
    "    build_with_TPU = False\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        BATCH_SIZE = strategy.num_replicas_in_sync * 64\n",
    "        print(f\"Running on TPU: {tpu.master()}\")\n",
    "        print(f\"Batch Size on TPU: {BATCH_SIZE}\")\n",
    "        build_with_TPU = True\n",
    "    except ValueError:\n",
    "        print(\"Not running on TPU\")\n",
    "        # strategy = tf.distribute.get_strategy()\n",
    "        # BATCH_SIZE = 512\n",
    "        # print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "        # print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "        \n",
    "    if build_with_TPU:\n",
    "        with strategy.scope():\n",
    "            model = Sequential([\n",
    "                Dense(units=512, kernel_initializer='random_normal', activation='gelu',\n",
    "                      input_shape=INPUT_SHAPE),\n",
    "                BatchNormalization(),\n",
    "                Dense(units=256, kernel_initializer='random_normal', activation='gelu'),\n",
    "                BatchNormalization(),\n",
    "                Dense(units=128, kernel_initializer='random_normal', activation='gelu'),\n",
    "                BatchNormalization(),\n",
    "                Dense(units=64, kernel_initializer='random_normal', activation='gelu'),\n",
    "                BatchNormalization(),\n",
    "                Dense(units=32, kernel_initializer='random_normal', activation='gelu'),\n",
    "                BatchNormalization(),\n",
    "                Dense(units=5, activation=\"softmax\")\n",
    "            ])\n",
    "            model.compile(\n",
    "                optimizer='adam',\n",
    "                loss = 'sparse_categorical_crossentropy',\n",
    "                metrics=[\"accuracy\"]\n",
    "            )\n",
    "    else:\n",
    "        model = Sequential([\n",
    "            Dense(units=512, kernel_initializer='random_normal', activation='gelu',\n",
    "                  input_shape=INPUT_SHAPE),\n",
    "            BatchNormalization(),\n",
    "            Dense(units=256, kernel_initializer='random_normal', activation='gelu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(units=128, kernel_initializer='random_normal', activation='gelu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(units=64, kernel_initializer='random_normal', activation='gelu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(units=32, kernel_initializer='random_normal', activation='gelu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(units=5, activation=\"softmax\")\n",
    "        ])\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss = 'sparse_categorical_crossentropy',\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "            \n",
    "    return model\n",
    "\n",
    "if plot:\n",
    "    plot_model(\n",
    "        build_model(),\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True\n",
    "    )\n",
    "else:\n",
    "    build_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9035cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T11:44:51.391982Z",
     "iopub.status.busy": "2021-12-13T11:44:51.390985Z",
     "iopub.status.idle": "2021-12-13T13:31:54.426575Z",
     "shell.execute_reply": "2021-12-13T13:31:54.427232Z",
     "shell.execute_reply.started": "2021-12-13T11:41:45.338305Z"
    },
    "papermill": {
     "duration": 6423.057941,
     "end_time": "2021-12-13T13:31:54.427434",
     "exception": false,
     "start_time": "2021-12-13T11:44:51.369493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs available:  1\n",
      "Not running on TPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 11:44:53.618138: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 791924980 exceeds 10% of free system memory.\n",
      "2021-12-13 11:44:54.483354: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 791924980 exceeds 10% of free system memory.\n",
      "2021-12-13 11:44:55.100053: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "Fold 1 Validation Accuracy: 0.9612689173748572\n",
      "Not running on TPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 11:56:30.919307: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 791924980 exceeds 10% of free system memory.\n",
      "2021-12-13 11:56:31.750051: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 791924980 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "Fold 2 Validation Accuracy: 0.961961481437033\n",
      "Not running on TPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 12:06:17.241386: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 791925200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Fold 3 Validation Accuracy: 0.9614638390647111\n",
      "Not running on TPU\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n",
      "Fold 4 Validation Accuracy: 0.9614288357393952\n",
      "Not running on TPU\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n",
      "Fold 5 Validation Accuracy: 0.9622814167345898\n",
      "Not running on TPU\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n",
      "Fold 6 Validation Accuracy: 0.9622314119841385\n",
      "Not running on TPU\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Fold 7 Validation Accuracy: 0.9616938609167871\n",
      "Not running on TPU\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Fold 8 Validation Accuracy: 0.9619663868067466\n",
      "Not running on TPU\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n",
      "Fold 9 Validation Accuracy: 0.9620263925072882\n",
      "Not running on TPU\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n",
      "Fold 10 Validation Accuracy: 0.9618563763557538\n",
      "\n",
      "\n",
      "Mean accuracy over all folds: 0.9618178918921302\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "FOLDS = 10\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 1024\n",
    "STEPS_PER_EPOCH = 2*BATCH_SIZE # Not used, chosen if wanted faster epochs\n",
    "test_preds = np.zeros((1,1))\n",
    "scores = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=0)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X,y), start=1):\n",
    "    X_train, X_val = X[train_idx], X[test_idx]\n",
    "    y_train, y_val = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = build_model()\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        # steps_per_epoch=4*BATCH_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Fold {fold} Validation Accuracy: {score}\")\n",
    "    scores.append(score)\n",
    "\n",
    "    test_preds = test_preds + model.predict(test_df)\n",
    "    \n",
    "    # del model, y_pred, score\n",
    "\n",
    "print(f\"\\n\\nMean accuracy over all folds: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37a0f63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-13T13:31:54.475558Z",
     "iopub.status.busy": "2021-12-13T13:31:54.475052Z",
     "iopub.status.idle": "2021-12-13T13:31:56.405686Z",
     "shell.execute_reply": "2021-12-13T13:31:56.405231Z",
     "shell.execute_reply.started": "2021-12-13T11:41:16.850135Z"
    },
    "papermill": {
     "duration": 1.956003,
     "end_time": "2021-12-13T13:31:56.405826",
     "exception": false,
     "start_time": "2021-12-13T13:31:54.449823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"../input/tabular-playground-series-dec-2021/sample_submission.csv\")\n",
    "preds = np.argmax(test_preds, axis=1)\n",
    "preds = encoder.inverse_transform(preds)\n",
    "\n",
    "sample.Cover_Type = preds\n",
    "sample.to_csv(\"Submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e850d",
   "metadata": {
    "papermill": {
     "duration": 0.02148,
     "end_time": "2021-12-13T13:31:56.448956",
     "exception": false,
     "start_time": "2021-12-13T13:31:56.427476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6464.166758,
   "end_time": "2021-12-13T13:31:59.595174",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-13T11:44:15.428416",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
